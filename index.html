<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="Guangze Zheng">
    <meta name="author" content="Guangze Zheng">
    <link rel="icon" href="files/github-mark.svg">

    <title>Guangze Zheng</title>

    <!-- Bootstrap core CSS -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta.2/css/bootstrap.min.css" integrity="sha384-PsH8R72JQ3SOdhVi3uxftmaW6Vc51MKb0q5P2rRUpPvrszuE4W1povHYgTpBfshb" crossorigin="anonymous">

    <!-- Custom styles for this template -->
    <link href="css/narrow-jumbotron.css" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-111714927-1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'UA-111714927-1');
    </script>
    
</head>

<style>
    ul {
      list-style-type: none;
    }
    
    li:before {
      content: "‚Ä¢";
      margin-right: 8px;
    }
    </style>
<body>


<div class="container">

    <main role="main">
        <div id="about" class="row marketing">

                <div class="col-lg-5 mt-5">
                    <figure class="figure">
                        <img width="120%" src="files/photo_2025.jpg" align="right" class="figure-img img-fluid rounded" alt="Me.">
                    </figure>
                </div>
                <div class="col-lg-6 mt-5 offset-lg-1">
                    <div class="row marketing" style="margin-top:0">
                        <h2>Guangze Zheng ÈÉëÂÖâÊ≥Ω</h2>
                    </div>
                    <div class="row marketing">
                        <p> üòÄ Welcome to my homepage. ‰Ω†Â•Ω! Hi! Salut! –ü—Ä–∏–≤–µ—Ç! „ÇÑ„ÅÇ! ÏïàÎÖï!
                        </p>
                        <p> üßë‚Äçüéì I'm a 3rd year PhD student at HKU CS department, advised by 
                            Prof. <a href="https://www.cs.hku.hk/people/academic-staff/jpan">Jia Pan</a>. Before that, I obtained my B.Eng. degree from Tongji University.
                            My research interests include visual tracking.
                        </p>
                    </div>
                    <div class="row marketing">
                        <p>üì™ <a href="mailto:guangze@connect.hku.hk">guangze@connect.hku.hk</a>
                            <br>
                            [<a href="https://github.com/George-Zhuang">Github</a>]
                            [<a href="https://scholar.google.com/citations?user=-kcZWRQAAAAJ&hl=en">Google Scholar</a>]
                        </p>
                    </div>
                </div>
        </div>
        <div id="News" class="row marketing">
            <div class="row" style="width:100%">
                <div class="col-lg-12">
                    <h4>üöÄ News</h4>
                    <hr>
                </div>
            </div>
            <ul>
                <li>
                    [<strong>NeurIPS 2025</strong>] <a href="https://george-zhuang.github.io/lbm/">LBM</a> has been accepted by NeurIPS 2025. LBM realizes efficient tracking anything.
                    [<a href=".">Paper</a>]
                    [<a href="https://george-zhuang.github.io/lbm/">Project</a>]
                    [<a href="https://github.com/George-Zhuang/LBM">Code</a>]. 
                </li>
                <li>
                    [<strong>CVPR 2024</strong>] <a href="https://george-zhuang.github.io/nettrack/">NetTrack</a> has been accepted by CVPR 2024. NetTrack aims to track highly dynamic (multiple) objects in the open world.
                    [<a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Zheng_NetTrack_Tracking_Highly_Dynamic_Objects_with_a_Net_CVPR_2024_paper.pdf">Paper</a>]
                    [<a href="https://george-zhuang.github.io/nettrack/">Project</a>]
                    [<a href="https://github.com/George-Zhuang/NetTrack">Code</a>].
                </li>
            </ul>
        </div>


        <div id="Featured Publications" class="row marketing">
            <div class="row" style="width:100%">
                <div class="col-lg-12">
                    <h4>üåü Featured Publications</h4>
                    <hr>
                </div>
            </div>

            <div class="row marketing mb-3">
                <div class="col-lg-6">
                    <video width="100%" controls>
                        <source src="./lbm/files/nips2025_demo.mp4" type="video/mp4">
                    </video>
                </div>

                <div class="col-lg-6 mt-3">
                    <h5><span class="font-italic">(NeurIPS 2025)</span>
                        Lattice Boltzmann Model for Learning Real-World Pixel Dynamicity
                        [<a href=".">Paper</a>]
                        [<a href="https://github.com/George-Zhuang/LBM">Code</a>]
                        [<a href="https://george-zhuang.github.io/lbm/">Project Page</a>]
                        [<a href="https://www.youtube.com/watch?v=d3YXxdgkEso">Youtube</a>]
                    </h5>
                    <p>
                    <strong>Guangze Zheng</strong>, Shijie Lin, Haobo Zuo, Si Si, Ming-Shan Wang, Changhong Fu, Jia Pan*
                    </p>
                </div>
            </div>

            <div class="row marketing mb-3">
                <div class="col-lg-6">
                    <video width="100%" controls>
                        <source src="./files/nc2024_demo.mp4" type="video/mp4">
                    </video>
                </div>

                <div class="col-lg-6 mt-3">
                    <h5><span class="font-italic">(Nature Communications 2024)</span>
                        Embodied neuromorphic synergy for lighting-robust machine vision to see in extreme bright
                        [<a href="https://www.nature.com/articles/s41467-024-54789-8">Paper</a>]
                    </h5>
                    <p>
                    Shijie Lin, <strong>Guangze Zheng</strong>, Ziwei Wang, Ruihua Han, Wanli Xing, Zeqing Zhang, Yifan Peng, Jia Pan
                    </p>
                </div>
            </div> 

            <div class="row marketing mb-3">
                <div class="col-lg-6">
                    <video width="100%" controls>
                        <source src="./nettrack/files/output.mp4" type="video/mp4">
                    </video>
                </div>

                <div class="col-lg-6 mt-3">
                    <h5><span class="font-italic">(CVPR 2024)</span>
                        NetTrack: Tracking Highly Dynamic Objects with a Net
                        [<a href=".">Paper</a>]
                        [<a href="https://github.com/George-Zhuang/NetTrack">Code</a>]
                        [<a href="https://george-zhuang.github.io/nettrack/">Project Page</a>]
                        [<a href="https://www.youtube.com/watch?v=h81R1B8HuOE">Youtube</a>]
                        [<a href="https://drive.google.com/drive/folders/140mPnOVZY-2apH76at9yYuVGIDWOvsH_?usp=sharing">Dataset</a>]
                    </h5>
                    <p>
                    <strong>Guangze Zheng</strong>, Shijie Lin, Haobo Zuo, Changhong Fu, Jia Pan*
                    </p>
                </div>
            </div>

            <div class="row marketing mb-3">
                <div class="col-lg-6">
                    <img class="img-thumbnail" src="files/SiamSA_TII.jpg" style="width:100%;max-height:200px"/>
                </div>

                <div class="col-lg-6 mt-3">
                    <h5><span class="font-italic">(TII 2022)</span>
                        Scale-Aware Siamese Object Tracking for Vision-Based UAM Approaching
                        [<a href="https://ieeexplore.ieee.org/document/9980457">Paper</a>]
                        [<a href="https://github.com/vision4robotics/SiamSA">Code</a>]
                        [<a href="https://george-zhuang.github.io/siamsa/">Project Page</a>]
                        [<a href="https://george-zhuang.github.io/siamsa/">Dataset</a>]
                        [<a href="https://www.youtube.com/watch?v=Fi6kESBBpnk">Youtube</a>]
                        [<a href="https://www.bilibili.com/video/BV1Me4y137eB">Bilibili</a>]
                    </h5>
                    <p><b>Guangze Zheng</b>, Changhong Fu, Junjie Ye, Bowen Li, Geng Lu, and Jia Pan</p>
                </div>
            </div>

            <div class="row marketing mb-3">
                <div class="col-lg-6">
                    <img class="img-thumbnail" src="files/UDAT_CVPR.jpg" style="width:100%;max-height:200px"/>
                </div>

                <div class="col-lg-6 mt-3">
                    <h5><span class="font-italic">(CVPR 2022)</span>
                        Unsupervised Domain Adaptation for Nighttime Aerial Tracking
                        [<a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Ye_Unsupervised_Domain_Adaptation_for_Nighttime_Aerial_Tracking_CVPR_2022_paper.pdf">Paper</a>]
                        [<a href="https://github.com/vision4robotics/UDAT">Code</a>]
                        [<a href="https://vision4robotics.github.io/NAT2021">Dataset</a>]
                        [<a href="https://www.youtube.com/watch?v=-nB5XitC-Lk">Video</a>]
                        [<a href="https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ye_Unsupervised_Domain_Adaptation_CVPR_2022_supplemental.pdf">Supplementary Material</a>]
                    </h5>
                    <p>Junjie Ye, Changhong Fu, <b>Guangze Zheng</b>, Danda Pani Paudel, and Guang Chen.</p>
                </div>
            </div>

            
            <div class="row marketing mb-3">
                <div class="col-lg-6">
                    <img class="img-thumbnail" src="files/SiamSA_IROS.jpg" style="width:100%;max-height:200px"/>
                </div>

                <div class="col-lg-6 mt-3">
                    <h5><span class="font-italic">(IROS 2022)</span>
                        Siamese Object Tracking for Vision-Based UAM Approaching with Pairwise Scale-Channel Attention
                        [<a href="https://arxiv.org/abs/2211.14564">Paper</a>]
                        [<a href="https://github.com/vision4robotics/SiamSA">Code</a>]
                        [<a href="https://george-zhuang.github.io/siamsa/">Project Page</a>]
                        [<a href="https://george-zhuang.github.io/siamsa/">Dataset</a>]
                        [<a href="https://www.youtube.com/watch?v=FS1tJolGGV8">Youtube</a>]
                        [<a href="https://www.bilibili.com/video/BV1TR4y1y7fb">Bilibili</a>]

                    </h5>
                    <p><b>Guangze Zheng</b>, Changhong Fu, Junjie Ye, Bowen Li, Geng Lu, and Jia Pan</p>
                </div>
            </div>

            <div class="row marketing mb-3">
                <div class="col-lg-6">
                    <img class="img-thumbnail" src="files/MSCF_ICRA.jpg" style="width:100%;max-height:200px"/>
                </div>

                <div class="col-lg-6 mt-3">
                    <h5><span class="font-italic">(ICRA 2021)</span>
                        Mutation Sensitive Correlation Filter for Real-Time UAV Tracking with Adaptive Hybrid Label
                        [<a href="https://arxiv.org/pdf/2106.08073.pdf">Paper</a>]
                        [<a href="https://github.com/vision4robotics/MSCF-tracker">Code</a>]
                        [<a href="https://www.youtube.com/watch?v=4EPGBCuatxU">Video</a>]
                    </h5>
                    <p><b>Guangze Zheng</b>, Changhong Fu, Junjie Ye, Fuling Lin, and Fangqiang Ding</p>
                </div>
            </div>


        </div>

        <div id="Co-Authored Publications" class="row marketing">
            <div class="row" style="width:100%">
                <div class="col-lg-12">
                    <h4>üì∞ Co-Authored Publications</h4>
                    <hr>
                </div>
            </div>
            <ul>
                <li>
                    <span class="font-italic">(IROS 2025)</span>
                    Simultaneous Synchronization and Calibration for Wide-baseline Stereo Event Cameras
                    [<a href="https://arxiv.org/abs/2309.16990.pdf">Paper</a>]
                </li>
                <li>
                    <span class="font-italic">(ICRAM 2024)</span>
                    SAM-DA: UAV Tracks Anything at Night with SAM-Powered Domain Adaptation
                    [<a href="https://arxiv.org/pdf/2307.01024.pdf">Paper</a>]
                    [<a href="https://github.com/vision4robotics/SAM-DA">Code</a>]
                </li>
                <li>
                    <span class="font-italic">(RA-L 2024)</span>
                    Understanding Particles from Video: Property Estimation of Granular Materials via Visuo-Haptic Learning
                    [<a href="https://ieeexplore.ieee.org/abstract/document/10777617/">Paper</a>]
                    [<a href="https://sites.google.com/view/gmwork/vhlearning">Video</a>]
                </li>
                <li>
                    <span class="font-italic">(AIR 2023)</span>
                    Siamese Object Tracking for Unmanned Aerial Vehicle: A Review and Comprehensive Analysis.
                    [<a href="https://arxiv.org/pdf/2205.04281.pdf">Paper</a>]
                    [<a href="https://github.com/vision4robotics/SiameseTracking4UAV">Code</a>]
                </li>
                <li>
                    <span class="font-italic">(RA-L 2023)</span>
                    Scale-Aware Domain Adaptation for Robust UAV Tracking.
                    [<a href="https://ieeexplore.ieee.org/document/10111056/">Paper</a>]
                    [<a href="https://github.com/vision4robotics/ScaleAwareDA">Code</a>]
                    [<a href="https://youtu.be/mIunErVTXPI">Video</a>]
                    
                </li>
                <li>
                    <span class="font-italic">(RA-L 2022)</span>
                    Tracker Meets Night: A Transformer Enhancer for UAV Tracking.
                    [<a href="https://ieeexplore.ieee.org/abstract/document/9696362">Paper</a>]
                    [<a href="https://github.com/vision4robotics/SCT">Code</a>]
                    [<a href="https://darktrack2021.netlify.app/">Dataset</a>]
                    [<a href="https://www.youtube.com/watch?v=Hm5olT0Ss-E">Video</a>]
                </li>
                <li>
                    <span class="font-italic">(IROS 2021)</span>
                    DarkLighter: Light up the Darkness for UAV Tracking.
                    [<a href="https://arxiv.org/pdf/2205.04281.pdf">Paper</a>]
                    [<a href="https://github.com/vision4robotics/DarkLighter">Code</a>]
                    [<a href="https://www.youtube.com/watch?v=rJtPST69J60">Video</a>]
                </li>
            </ul>
        </div>


    </main>

    <footer class="footer">
    <p>&copy; The design of this page was based on <a href="https://www.guandaoyang.com/" target="_blank">Guandao Yang</a>'s website 2018.</p>
    </footer>

</div> <!-- /container -->
</body>
</html>
